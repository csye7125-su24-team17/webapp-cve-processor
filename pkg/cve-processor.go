package pkg

import (
	"fmt"
	"log"
	"math"
	"os"
	"path/filepath"
	"strconv"
	"sync"

	"github.com/IBM/sarama"
)

func splitYears(start int,end int,numGroups int)[][]int{
	var result [][]int
	totalYears := end - start + 1
	groupSize := int(math.Ceil(float64(totalYears) / float64(numGroups)))

	for i := 0; i < totalYears; i += groupSize {
		end := int(math.Min(float64(start+i+groupSize-1), float64(end)))
		var group []int
		for j := start + i; j <= end; j++ {
			group = append(group, j)
		}
		result = append(result, group)
	}

	return result
}

func PushToKafka(rootPath string) {
	var wg sync.WaitGroup
	goroutines := os.Getenv("go_routines")
	noofgoroutines, err := strconv.Atoi(goroutines)
	if err != nil {
		fmt.Println("Error:", err)
		return
	}
	yearGroups := splitYears(1999, 2024, noofgoroutines)
	for _, group := range yearGroups {
		wg.Add(1)
		go func(group []int, rootPath string) {
			defer wg.Done()
			for _, year := range group {
				subPath := fmt.Sprintf("%s/%d", rootPath, year)
				fmt.Println("Processing folder:", subPath)
				processFolder(subPath)
			}
		}(group,rootPath)
	}
	wg.Wait()
}
func processFolder(subPath string) {
	err := filepath.Walk(subPath, func(path string, info os.FileInfo, err error) error {
		if err != nil {
			return err 
		}
		if filepath.Ext(path) == ".json" { // Only process files with a .json extension
			processFile(path)
		}
		return nil
	})
	if err != nil {
		log.Printf("Error walking through CVE directory: %v", err)
	}
}

// processFile reads and processes a single JSON file from the given path.
func processFile(path string) {

	// Get the file name
	fileName := filepath.Base(path)

	// Skip delta.json and deltaLog.json files
	if fileName == "delta.json" || fileName == "deltaLog.json" {
		log.Printf("Skipping file: %s", fileName)
		return
	}
	data, err := os.ReadFile(path) // Read the file content
	if err != nil {
		log.Printf("Error reading file %s: %v", path, err)
		return
	}
	kafkaTopic := os.Getenv("kafka_topic")
	pushToTopic(kafkaTopic, data)
}

func ConnectProducer(brokersUrl []string)(sarama.SyncProducer, error){
	config := sarama.NewConfig()
	config.Producer.Return.Successes = true
	config.Producer.RequiredAcks = sarama.WaitForAll
	config.Producer.Retry.Max = 5
	conn,err:= sarama.NewSyncProducer(brokersUrl,config)
	if err!=nil{
		return nil, err
	}
	return conn,nil
}

func pushToTopic(topic string, jsonData []byte) error {
	kafkaHost := os.Getenv("kafka_host")
	kafkaPort := os.Getenv("kafka_port")
	kafkaUrl := fmt.Sprintf("%s:%s",kafkaHost,kafkaPort)
	brokersUrl := []string{kafkaUrl}
	producer, err := ConnectProducer(brokersUrl)
	if err!=nil{
		return err
	}
	defer producer.Close()
	msg := &sarama.ProducerMessage{
		Topic: topic,
		Value: sarama.StringEncoder(jsonData),
	}
	partition, offset, err := producer.SendMessage(msg)
	if err != nil{
		return err
	}
	fmt.Printf("Message is stored in topic(%s)/partition(%d)/offset(%d)\n",topic,partition,offset)
	return nil
}